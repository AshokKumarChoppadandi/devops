---
- name: Install and Configure Apache Hadoop
  hosts: localservers
  become: true

  vars:
    HADOOP_VERSION: 2.8.0

  tasks:
    - name: Upgrade OS Packages
      # dnf:
      yum:
        name: '*'
        state: latest
        update_cache: yes

    - name: Install Open JDK 8
      # dnf:
      yum:
        name: java-1.8.0-openjdk-devel
        state: present

    - name: Download and Untar Apache Hadoop
      unarchive:
        src: 'https://archive.apache.org/dist/hadoop/hadoop-{{ HADOOP_VERSION }}.tar.gz'
        dest: /usr/local
        remote_src: yes
        creates: '/usr/local/hadoop-{{ HADOOP_VERSION }}'

    - name: Create Hadoop Directory Soft Link
      file:
        src: '/usr/local/hadoop-{{ HADOOP_VERSION }}'
        dest: '/usr/local/hadoop'
        state: link

    - name: Setting up JAVA_HOME HADOOP_HOME and PATH Variables
      blockinfile:
        path: /etc/profile
        insertafter: 'EOF'
        block: |2
          
          # Setting up JAVA_HOME
          export JAVA_HOME=/usr/lib/jvm/java
          
          # Setting up HADOOP_HOME
          export HADOOP_HOME=/usr/local/hadoop
          
          # Setting up HADOOP_CONF_DIR
          export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
          
          # Adding JAVA & HADOOP Binaries to PATH Variable
          export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

        state: present
        backup: true

    - name: Creating Hadoop data directories
      file:
        path: '{{ item }}'
        state: directory
      loop:
        - /usr/local/hadoop/data/tmp
        - /usr/local/hadoop/data/namenode
        - /usr/local/hadoop/data/datanode
        - /usr/local/hadoop/data/namesecondary

    - name: Configuring core-site.xml
      blockinfile:
        path: /usr/local/hadoop/etc/hadoop/core-site.xml
        insertafter: <configuration>
        block: |2
              <property>
                <name>hadoop.tmp.dir</name>
                <value>/usr/local/hadoop/data/tmp</value>
              </property>
              <property>
                <name>fs.default.name</name>
                <value>hdfs://{{ inventory_hostname }}:9000</value>
              </property>
        state: present
        backup: true

    - name: Configuring hdfs-site.xml
      blockinfile:
        path: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
        insertafter: <configuration>
        block: |2
                  <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>/usr/local/hadoop/data/namenode</value>
                  </property>
                  <property>
                    <name>dfs.datanode.data.dir</name>
                    <value>/usr/local/hadoop/data/datanode</value>
                  </property>
                  <property>
                    <name>dfs.namenode.checkpoint.dir</name>
                    <value>/usr/local/hadoop/data/namesecondary</value>
                  </property>
                  <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                  </property>
                  <property>
                    <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
                    <value>false</value>
                  </property>
        state: present
        backup: true

    - name: Checking whether Namenode requires format or not
      find:
        paths: /usr/local/hadoop/data/namenode
        file_type: any
        patterns: "current,in_use.lock"
      register: matched_result

    - name: Format Namenode
      shell: |
        source /etc/profile
        hdfs namenode -format
      when: matched_result.matched == 0

    - name: Creating Namenode systemd service file
      file:
        path: /etc/systemd/system/namenode.service
        state: touch
        owner: root
        group: root
        mode: 0644

    - name: Configuring Namenode service as systemd service
      copy:
        dest: /etc/systemd/system/namenode.service
        content: |
          [Unit]
          Description=Hadoop Namenode Service
          
          [Service]
          Type=forking
          Environment=JAVA_HOME=/usr/lib/jvm/java
          Environment=HADOOP_HOME=/usr/local/hadoop
          Environment=HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
          ExecStart=/usr/local/hadoop/sbin/hadoop-daemon.sh start namenode
          ExecStop=/usr/local/hadoop/sbin/hadoop-daemon.sh stop namenode
          
          [Install]
          WantedBy=multi-user.target

    - name: Start Namenode Service
      systemd:
        daemon_reload: true
        enabled: true
        name: namenode
        state: started








